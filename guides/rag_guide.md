# ğŸ“š RAG æ£€ç´¢å¢å¼ºç”ŸæˆæŒ‡å—

> **ç‰ˆæœ¬**ï¼šv1.5.0 | **æ›´æ–°**ï¼š2024-12-14

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨ RAGï¼ˆRetrieval-Augmented Generationï¼‰æŠ€æœ¯ï¼Œå°† Investment Masters Handbook çš„ 17 ä½å¤§å¸ˆæ™ºæ…§åº”ç”¨åˆ°å®é™…æŠ•èµ„å†³ç­–ä¸­ã€‚

---

## ä»€ä¹ˆæ˜¯ RAGï¼Ÿ

**RAGï¼ˆRetrieval-Augmented Generationï¼‰** = æ£€ç´¢ + å¢å¼º + ç”Ÿæˆ

```
ä¼ ç»Ÿ LLMï¼š
ç”¨æˆ·é—®é¢˜ â†’ LLM â†’ ç­”æ¡ˆï¼ˆå—é™äºè®­ç»ƒæ•°æ®ï¼‰

RAG å¢å¼ºï¼š
ç”¨æˆ·é—®é¢˜ â†’ æ£€ç´¢ç›¸å…³çŸ¥è¯† â†’ LLM + çŸ¥è¯†åº“ â†’ æ›´å‡†ç¡®çš„ç­”æ¡ˆ
          â†‘
    Investment Masters
    Handbook çŸ¥è¯†åº“
```

### ä¸ºä»€ä¹ˆéœ€è¦ RAGï¼Ÿ

| åœºæ™¯ | ä¼ ç»Ÿ LLM | RAG å¢å¼º |
|------|----------|----------|
| **æ—¶æ•ˆæ€§** | è®­ç»ƒæˆªæ­¢æ—¥æœŸå‰çš„æ•°æ® | å®æ—¶æ›´æ–°çš„çŸ¥è¯†åº“ |
| **å‡†ç¡®æ€§** | å¯èƒ½äº§ç”Ÿå¹»è§‰ | åŸºäºçœŸå®æ–‡æ¡£çš„å¼•ç”¨ |
| **ä¸“ä¸šæ€§** | é€šç”¨çŸ¥è¯† | 17 ä½æŠ•èµ„å¤§å¸ˆçš„ä¸“ä¸šæ™ºæ…§ |
| **å¯æº¯æº** | æ— æ³•è¿½è¸ªæ¥æº | å¯è¿½æº¯åˆ°å…·ä½“çš„å¤§å¸ˆå’Œè§„åˆ™ |

---

## é¡¹ç›®ä¸­çš„ RAG æ¶æ„

```mermaid
flowchart LR
    subgraph sources [çŸ¥è¯†æ¥æº]
        A1[17ä½æŠ•èµ„è€…MDæ–‡æ¡£]
        A2[232æ¡IF-THENè§„åˆ™]
        A3[6ä¸ªç¥çº§Prompt]
        A4[AI500ç­–ç•¥é…ç½®]
    end
    
    subgraph processing [å¤„ç†æµç¨‹]
        B1[æ–‡æ¡£åˆ†å—]
        B2[å‘é‡åŒ–Embedding]
        B3[å‘é‡æ•°æ®åº“]
    end
    
    subgraph query [æŸ¥è¯¢æµç¨‹]
        C1[ç”¨æˆ·é—®é¢˜]
        C2[è¯­ä¹‰æ£€ç´¢]
        C3[ç›¸å…³æ–‡æ¡£]
        C4[LLMç”Ÿæˆç­”æ¡ˆ]
    end
    
    sources --> processing
    processing --> query
    C1 --> C2
    C2 --> C3
    C3 --> C4
```

---

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# åŸºç¡€ RAG ä¾èµ–
pip install langchain langchain-community chromadb pyyaml

# å¦‚æœéœ€è¦æ›´å¥½çš„ embeddingï¼ˆå¯é€‰ï¼‰
pip install sentence-transformers

# å¦‚æœä½¿ç”¨ OpenAIï¼ˆå¯é€‰ï¼‰
pip install openai
```

### 2. åŸºç¡€æŸ¥è¯¢

```bash
# å•æ¬¡æŸ¥è¯¢
python examples/rag_langchain.py "å¸‚åœºææ…Œæ—¶è¯¥æ€ä¹ˆåŠï¼Ÿ"

# äº¤äº’æ¨¡å¼
python examples/rag_langchain.py --interactive

# ä»…æ£€ç´¢è§„åˆ™ï¼ˆæ›´å¿«ï¼‰
python examples/rag_langchain.py --rules-only "æŠ¤åŸæ²³"
```

### 3. æŒä¹…åŒ–å‘é‡åº“

```bash
# é¦–æ¬¡è¿è¡Œï¼Œåˆ›å»ºå¹¶ä¿å­˜å‘é‡åº“
python examples/rag_langchain.py --persist ./vectorstore "å·´è²ç‰¹å¦‚ä½•é€‰è‚¡ï¼Ÿ"

# åç»­ä½¿ç”¨å·²ä¿å­˜çš„å‘é‡åº“ï¼ˆæ›´å¿«ï¼‰
python examples/rag_langchain.py --load ./vectorstore "èŠ’æ ¼çš„å†³ç­–æ¸…å•"
```

---

## æ ¸å¿ƒåŠŸèƒ½

### 1. æŠ•èµ„è€…æ–‡æ¡£æ£€ç´¢

**é€‚ç”¨åœºæ™¯**ï¼šéœ€è¦æ·±å…¥ç†è§£æŸä½å¤§å¸ˆçš„å®Œæ•´æ¡†æ¶

```python
from examples.rag_langchain import load_investor_documents, create_vectorstore

# åŠ è½½æ‰€æœ‰æŠ•èµ„è€…æ–‡æ¡£
docs = load_investor_documents()
vectorstore = create_vectorstore(docs)

# æ£€ç´¢ç›¸å…³å†…å®¹
results = vectorstore.similarity_search(
    "å·´è²ç‰¹å¦‚ä½•è¯„ä¼°æŠ¤åŸæ²³ï¼Ÿ",
    k=3
)
```

**è¿”å›å†…å®¹**ï¼š
- æŠ•èµ„è€… Markdown æ–‡æ¡£çš„ç›¸å…³æ®µè½
- å…ƒæ•°æ®ï¼šæŠ•èµ„è€… IDã€ä¸­æ–‡åã€æŠ•èµ„é£æ ¼ã€æ“…é•¿é¢†åŸŸ

---

### 2. å†³ç­–è§„åˆ™æ£€ç´¢

**é€‚ç”¨åœºæ™¯**ï¼šéœ€è¦å¿«é€Ÿè·å–å¯æ‰§è¡Œçš„ IF-THEN è§„åˆ™

```python
from examples.rag_langchain import load_decision_rules

# åŠ è½½ 232 æ¡å†³ç­–è§„åˆ™
rules = load_decision_rules()

# æ£€ç´¢
results = vectorstore.similarity_search(
    "å¸‚åœºæš´è·Œæ—¶åº”è¯¥å¦‚ä½•åº”å¯¹ï¼Ÿ",
    k=5
)
```

**è¿”å›å†…å®¹**ï¼š
- IF-THEN-BECAUSE æ ¼å¼çš„è§„åˆ™
- å…ƒæ•°æ®ï¼šæŠ•èµ„è€… IDã€è§„åˆ™ç±»å‹ï¼ˆentry/exit/risk_managementï¼‰

---

### 3. æ··åˆæ£€ç´¢

**é€‚ç”¨åœºæ™¯**ï¼šå…¨é¢äº†è§£æŸä¸ªä¸»é¢˜

```python
# åŒæ—¶åŠ è½½æ–‡æ¡£ + è§„åˆ™
investor_docs = load_investor_documents()
rule_docs = load_decision_rules()
all_docs = investor_docs + rule_docs

vectorstore = create_vectorstore(all_docs)

# æ£€ç´¢ä¼šåŒæ—¶è¿”å›æ–‡æ¡£æ®µè½å’Œå†³ç­–è§„åˆ™
results = vectorstore.similarity_search(
    "å¦‚ä½•åˆ¤æ–­å‘¨æœŸä½ç½®ï¼Ÿ",
    k=10
)
```

---

## é«˜çº§ç”¨æ³•

### 1. å¤šè½®å¯¹è¯ RAG

```python
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI

# åˆ›å»ºå¯¹è¯é“¾
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)

qa_chain = ConversationalRetrievalChain.from_llm(
    llm=ChatOpenAI(model="gpt-4"),
    retriever=vectorstore.as_retriever(search_kwargs={"k": 5}),
    memory=memory
)

# å¤šè½®å¯¹è¯
response1 = qa_chain({"question": "å·´è²ç‰¹å¦‚ä½•é€‰è‚¡ï¼Ÿ"})
response2 = qa_chain({"question": "é‚£èŠ’æ ¼å‘¢ï¼Ÿ"})  # ä¿ç•™ä¸Šä¸‹æ–‡
```

---

### 2. æŒ‰æŠ•èµ„è€…è¿‡æ»¤

```python
# åªæ£€ç´¢ç‰¹å®šæŠ•èµ„è€…çš„å†…å®¹
results = vectorstore.similarity_search(
    "æŠ¤åŸæ²³åˆ†æ",
    k=5,
    filter={"investor_id": "warren_buffett"}
)
```

---

### 3. æŒ‰è§„åˆ™ç±»å‹è¿‡æ»¤

```python
# åªæ£€ç´¢å…¥åœºè§„åˆ™
results = vectorstore.similarity_search(
    "ä»€ä¹ˆæ—¶å€™ä¹°å…¥ï¼Ÿ",
    k=5,
    filter={"kind": "entry"}
)

# åªæ£€ç´¢é£æ§è§„åˆ™
results = vectorstore.similarity_search(
    "å¦‚ä½•æ­¢æŸï¼Ÿ",
    k=5,
    filter={"kind": "risk_management"}
)
```

---

### 4. ä¸ NOFX AI500 ç­–ç•¥é›†æˆ

```python
# åŠ è½½ AI500 ç­–ç•¥æ–‡æ¡£
import json

with open("strategies/nofx_ai500_quantified.json", "r", encoding="utf-8") as f:
    ai500_config = json.load(f)

# æ„å»ºæŸ¥è¯¢ä¸Šä¸‹æ–‡
prompt_sections = ai500_config["config"]["prompt_sections"]

# æ£€ç´¢ç›¸å…³å¤§å¸ˆæ™ºæ…§
query = "å¦‚ä½•åˆ¤æ–­ OI å¢åŠ  + ä»·æ ¼ä¸Šæ¶¨çš„åèº«æ€§å¯åŠ¨ï¼Ÿ"
results = vectorstore.similarity_search(query, k=3)

# ç»“åˆ Soros åèº«æ€§ç†è®º + AI500 è§„åˆ™
```

---

## å®æˆ˜åœºæ™¯

### åœºæ™¯ 1ï¼šæŠ•èµ„å†³ç­–è¾…åŠ©

```python
# ç”¨æˆ·é—®é¢˜
question = "ç‰¹æ–¯æ‹‰ P/E 60ï¼ŒPEG 1.8ï¼Œå€¼å¾—ä¹°å—ï¼Ÿ"

# RAG æ£€ç´¢
results = vectorstore.similarity_search(question, k=5)

# å¯èƒ½è¿”å›ï¼š
# - Lynch çš„ PEG < 1 è§„åˆ™
# - Buffett çš„èƒ½åŠ›åœˆè­¦å‘Š
# - Munger çš„ä¼°å€¼åè¯¯æ£€æŸ¥
```

---

### åœºæ™¯ 2ï¼šå¸‚åœºæƒ…ç»ªåˆ¤æ–­

```python
# ç”¨æˆ·é—®é¢˜
question = "VIX æä½ï¼Œæ•£æˆ·æ¶Œå…¥ï¼Œè¿™æ˜¯ä»€ä¹ˆä¿¡å·ï¼Ÿ"

# RAG æ£€ç´¢ä¼šè¿”å›ï¼š
# - Marks çš„å‘¨æœŸä½ç½®åˆ¤æ–­
# - Burry çš„æ³¡æ²«è¯†åˆ«æ¸…å•
# - Druckenmiller çš„æµåŠ¨æ€§è­¦å‘Š
```

---

### åœºæ™¯ 3ï¼šé£é™©æ£€æŸ¥

```python
# ç”¨æˆ·é—®é¢˜
question = "æˆ‘æƒ³æ»¡ä»“ä¸€åªæˆé•¿è‚¡ï¼Œæœ‰ä»€ä¹ˆé£é™©ï¼Ÿ"

# RAG æ£€ç´¢ä¼šè¿”å›ï¼š
# - Thorp çš„å‡¯åˆ©å…¬å¼ä»“ä½å»ºè®®
# - Klarman çš„å®‰å…¨è¾¹é™…è¦æ±‚
# - Munger çš„å†³ç­–åè¯¯æ¸…å•
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. Embedding æ¨¡å‹é€‰æ‹©

| æ¨¡å‹ | ä¼˜ç‚¹ | ç¼ºç‚¹ | ä½¿ç”¨åœºæ™¯ |
|------|------|------|----------|
| **HuggingFace MiniLM** | å…è´¹ã€æœ¬åœ°è¿è¡Œ | ç²¾åº¦è¾ƒä½ | å¼€å‘æµ‹è¯• |
| **OpenAI text-embedding-ada-002** | é«˜ç²¾åº¦ | ä»˜è´¹ã€éœ€è”ç½‘ | ç”Ÿäº§ç¯å¢ƒ |
| **BGE-large-zh** | ä¸­æ–‡ä¼˜åŒ– | æ¨¡å‹è¾ƒå¤§ | ä¸­æ–‡ä¸ºä¸» |

```python
# ä½¿ç”¨ OpenAI Embedding
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
vectorstore = Chroma.from_documents(documents, embeddings)
```

---

### 2. å‘é‡åº“æŒä¹…åŒ–

```python
# é¦–æ¬¡åˆ›å»ºå‘é‡åº“ï¼ˆè€—æ—¶ï¼‰
vectorstore = Chroma.from_documents(
    documents,
    embeddings,
    persist_directory="./vectorstore"
)
vectorstore.persist()

# åç»­åŠ è½½ï¼ˆå¿«é€Ÿï¼‰
from langchain_community.vectorstores import Chroma

vectorstore = Chroma(
    persist_directory="./vectorstore",
    embedding_function=embeddings
)
```

---

### 3. åˆ†å—ç­–ç•¥ä¼˜åŒ–

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

# æŠ•èµ„è€…æ–‡æ¡£ï¼šè¾ƒå¤§å—ï¼ˆä¿ç•™å®Œæ•´ä¸Šä¸‹æ–‡ï¼‰
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    separators=["\n## ", "\n### ", "\n\n", "\n"]
)

# å†³ç­–è§„åˆ™ï¼šå°å—ï¼ˆæ¯æ¡è§„åˆ™ç‹¬ç«‹ï¼‰
rule_splitter = RecursiveCharacterTextSplitter(
    chunk_size=300,
    chunk_overlap=0
)
```

---

## æ—  RAG çš„ç®€åŒ–æ–¹æ¡ˆ

### 1. å…³é”®è¯æœç´¢

```python
from examples.rag_langchain import simple_keyword_search

# æ— éœ€å®‰è£… LangChain/ChromaDB
results = simple_keyword_search("æŠ¤åŸæ²³")

# è¿”å›åŒ…å«å…³é”®è¯çš„è§„åˆ™
for rule in results:
    print(f"IF {rule['when']}")
    print(f"THEN {rule['then']}")
```

---

### 2. ç›´æ¥åŠ è½½ JSON è§„åˆ™

```python
import json

with open("config/decision_rules.generated.json", "r", encoding="utf-8") as f:
    data = json.load(f)

# æŒ‰æŠ•èµ„è€…è¿‡æ»¤
buffett_rules = [
    r for r in data["rules"]
    if r["investor_id"] == "warren_buffett"
]
```

---

### 3. ä½œä¸º System Prompt

```python
# åŠ è½½æµ“ç¼©ç‰ˆæ¡†æ¶
with open("guides/llm_summary.md", "r", encoding="utf-8") as f:
    system_prompt = f.read()

# ç›´æ¥ä½œä¸º System Prompt
messages = [
    {"role": "system", "content": system_prompt},
    {"role": "user", "content": "ç‰¹æ–¯æ‹‰å€¼å¾—ä¹°å—ï¼Ÿ"}
]
```

---

## æœ€ä½³å®è·µ

### 1. æ£€ç´¢å‚æ•°è°ƒä¼˜

```python
# k å€¼ï¼šè¿”å›ç»“æœæ•°é‡
# - å¤ªå°ï¼ˆk=1-2ï¼‰ï¼šå¯èƒ½é—æ¼é‡è¦ä¿¡æ¯
# - å¤ªå¤§ï¼ˆk>10ï¼‰ï¼šå¼•å…¥å™ªéŸ³
# - æ¨èï¼šk=5

results = vectorstore.similarity_search(query, k=5)

# ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤
results_with_score = vectorstore.similarity_search_with_score(query, k=10)
filtered = [(doc, score) for doc, score in results_with_score if score < 0.5]
```

---

### 2. å¤šæŠ•èµ„è€…èåˆ

```python
# åœºæ™¯ï¼šéœ€è¦å¤šä½å¤§å¸ˆçš„è§†è§’
question = "ç¾è”å‚¨åŠ æ¯ï¼Œå¸‚åœºæš´è·Œï¼Œè¯¥æ€ä¹ˆåŠï¼Ÿ"

# åˆ†åˆ«æ£€ç´¢ä¸åŒå¤§å¸ˆ
results_marks = vectorstore.similarity_search(
    question,
    k=2,
    filter={"investor_id": "howard_marks"}
)

results_druck = vectorstore.similarity_search(
    question,
    k=2,
    filter={"investor_id": "stanley_druckenmiller"}
)

# èåˆç­”æ¡ˆ
combined_context = results_marks + results_druck
```

---

### 3. ä¸å®æ—¶æ•°æ®ç»“åˆ

```python
# æµç¨‹ï¼šå®æ—¶æ•°æ® â†’ RAG æ£€ç´¢ â†’ å†³ç­–å»ºè®®

# 1. è·å–å®æ—¶æ•°æ®
current_data = {
    "VIX": 35,
    "Fed_balance_sheet": "ç¼©è¡¨ä¸­",
    "credit_spread": "æ‰©å¤§"
}

# 2. æ„å»ºæŸ¥è¯¢
query = f"VIX {current_data['VIX']}, Fed æ­£åœ¨{current_data['Fed_balance_sheet']}"

# 3. æ£€ç´¢ç›¸å…³è§„åˆ™
results = vectorstore.similarity_search(query, k=5)

# 4. ç”Ÿæˆå†³ç­–
# ...
```

---

## å¸¸è§é—®é¢˜

### Q1: RAG æ£€ç´¢é€Ÿåº¦æ…¢æ€ä¹ˆåŠï¼Ÿ

**A**: 
1. ä½¿ç”¨ `--persist` æŒä¹…åŒ–å‘é‡åº“
2. ä½¿ç”¨ `--rules-only` åªåŠ è½½è§„åˆ™ï¼ˆæ›´å¿«ï¼‰
3. å‡å°‘æ–‡æ¡£æ•°é‡ï¼ˆæŒ‰æŠ•èµ„è€…è¿‡æ»¤ï¼‰
4. ä½¿ç”¨æ›´å°çš„ embedding æ¨¡å‹

---

### Q2: æ£€ç´¢ç»“æœä¸ç›¸å…³æ€ä¹ˆåŠï¼Ÿ

**A**: 
1. è°ƒæ•´æŸ¥è¯¢æªè¾ï¼ˆæ›´å…·ä½“ï¼‰
2. å¢åŠ  k å€¼ï¼ˆå¤šè¿”å›å‡ ä¸ªç»“æœï¼‰
3. ä½¿ç”¨æ›´å¥½çš„ embedding æ¨¡å‹
4. ä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤

---

### Q3: ä¸­æ–‡æŸ¥è¯¢æ•ˆæœä¸å¥½ï¼Ÿ

**A**: 
1. ä½¿ç”¨ä¸­æ–‡ä¼˜åŒ–çš„ embeddingï¼ˆå¦‚ BGE-large-zhï¼‰
2. æ··åˆä¸­è‹±æ–‡å…³é”®è¯
3. ä½¿ç”¨å…³é”®è¯æœç´¢æ›¿ä»£

---

### Q4: å¦‚ä½•é›†æˆåˆ° NOFX äº¤æ˜“ç³»ç»Ÿï¼Ÿ

**A**:
å‚è€ƒ [`guides/nofx_integration.md`](./nofx_integration.md) å’Œ [`prompts/nofx_ai500_master.md`](../prompts/nofx_ai500_master.md)

---

## ç›¸å…³èµ„æº

| èµ„æº | è¯´æ˜ |
|------|------|
| [`examples/rag_langchain.py`](../examples/rag_langchain.py) | RAG å®ç°ä»£ç  |
| [`config/decision_rules.generated.json`](../config/decision_rules.generated.json) | 232 æ¡å†³ç­–è§„åˆ™ |
| [`guides/llm_summary.md`](./llm_summary.md) | System Prompt æ¨¡æ¿ |
| [`guides/nofx_integration.md`](./nofx_integration.md) | NOFX é›†æˆæŒ‡å— |

---

## æŠ€æœ¯æ ˆ

- **LangChain**: RAG æ¡†æ¶
- **ChromaDB**: å‘é‡æ•°æ®åº“
- **Sentence Transformers**: Embedding æ¨¡å‹
- **YAML/JSON**: çŸ¥è¯†åº“æ ¼å¼

---

> **æç¤º**ï¼šRAG æ˜¯å·¥å…·ï¼ŒæŠ•èµ„å†³ç­–çš„æ ¸å¿ƒä»ç„¶æ˜¯ä½ çš„åˆ¤æ–­ã€‚å¤§å¸ˆçš„æ™ºæ…§æ˜¯å‚è€ƒï¼Œä¸æ˜¯ç­”æ¡ˆã€‚


